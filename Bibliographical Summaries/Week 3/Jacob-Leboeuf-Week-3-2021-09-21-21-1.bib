@article{edseee.879464120191101,
Abstract = {Shader lamp systems augment the real environment by projecting new textures on known target geometries. In dynamic scenes, object tracking maintains the illusion if the physical and virtual objects are well aligned. However, traditional trackers based on texture or contour information are often distracted by the projected content and tend to fail. In this paper, we present a model-based tracking strategy, which directly takes advantage from the projected content for pose estimation in a projector-camera system. An iterative pose estimation algorithm captures and exploits visible distortions caused by object movements. In a closed-loop, the corrected pose allows the update of the projection for the subsequent frame. Synthetic frames simulating the projection on the model are rendered and an optical flow-based method minimizes the difference between edges of the rendered and the camera image. Since the thresholds automatically adapt to the synthetic image, a complicated radiometric cali},
Author = {Gard, N. and Hilsmann, A. and Eisert, P.},
ISSN = {1077-2626},
Journal = {IEEE Transactions on Visualization and Computer Graphics, Visualization and Computer Graphics, IEEE Transactions on, IEEE Trans. Visual. Comput. Graphics},
Keywords = {Computing and Processing, Bioengineering, Signal Processing and Analysis, Cameras, Three-dimensional displays, Pose estimation, Mathematical model, Calibration, Object tracking, Projector-camera systems, projector-camera calibration, shader lamp systems, object tracking, object registration, spatial augmented reality, projection mapping},
Number = {11},
Pages = {3105 - 3113},
Title = {Projection Distortion-based Object Tracking in Shader Lamp Scenarios.},
Volume = {25},
URL = {https://umasslowell.idm.oclc.org/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=edseee&AN=edseee.8794641&site=eds-live},
Year = {2019},
}